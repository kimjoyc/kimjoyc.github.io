<!DOCTYPE HTML>
<!--
	Massively by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>MSSE</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Header -->
					<header id="header">
						<a href="index.html" class="logo">MSSE</a>
					</header>

				<!-- Nav -->
					<nav id="nav">
						<ul class="links">
							<li><a href="index.html">Relevant Projects</a></li>
							<li><a href="generic.html">About Me</a></li>
							<li><a href="elements.html">Certifications</a></li>
							<li class="active"><a href="msse.html">MSSE</a></li>
						</ul>
						<ul class="icons">
							<li><a href="#" class="icon brands fa-twitter"><span class="label">Twitter</span></a></li>
							<li><a href="#" class="icon brands fa-facebook-f"><span class="label">Facebook</span></a></li>
							<li><a href="#" class="icon brands fa-instagram"><span class="label">Instagram</span></a></li>
							<li><a href="https://github.com/kimjoyc?tab=repositories" class="icon brands fa-github"><span class="label">GitHub</span></a></li>
						</ul>
					</nav>

				<!-- Main -->
					<div id="main">

						<!-- Post -->
							<section class="post">
								<header class="major">
									<h1>Molecular Science <br />
									Software Engineering Concepts</h1>
								</header>
								
								<!-- Text stuff -->
				
								<hr />
								<header>
									<h2>MolecularNodes</h2>
									<p>Highlighting Python Programming Skill</p>
								</header>
								<p>I applied my Python programming expertise to improve the open-source MolecularNodes Blender plugin by adding a solvation shell visualization feature. This involved managing package dependencies, creating a user-friendly interface for inputting relevant information, and contributing to the open-source library by writing Python code to interface with the information for processing solvation shells into Blender for visualization. I also utilized Blender's rendering capabilities to visualize solvation shells around molecules in Blender, resulting in a significant enhancement in the plugin's usability. 
								</p>
								<p>Best Software Practices</p>
								<p>In this project, I followed best software engineering practices by thoroughly documenting the code using comments to explain the purpose of functions, variables, and classes. This increased the code's readability and made it easier for other developers to understand and contribute to the project. I also implemented testing to ensure that new features did not break existing functionality. End-to-end testing was done using Python to ensure that the software product was reliable and met user requirements. 
								</p>
								<p>Software Development Management Experience</p>
								<p>I highlighted my software development management experience through my Capstone project, the MolecularNodes Blender Plug-In. As the project leader, I applied the fundamentals of software project management by creating a comprehensive project plan, delegating tasks to team members, and ensuring the project was delivered on time and within budget. To effectively manage the project, I utilized software productivity tools such as Google Sheets to track progress, manage team communication, and resolve issues.
								</p>
								<p>Algorithmic Competence</p>
								<p>I utilized existing algorithmic libraries in innovative ways. For instance, the SolvationAnalysis library for MDAnalysis can be leveraged to process computationally intensive reads of molecular dynamics simulation trajectories in open-source software such as the MolecularNodes Blender plugin. As an example, I utilized the SolvationAnalysis library to extend the pre-existing molecular dynamics feature of the MolecularNodes plugin, allowing for the visualization of solvation shells. This type of integration of existing packages and libraries in creative ways demonstrates proficiency in algorithm design and optimization and illustrates a broader skill set that extends beyond knowledge of a specific software package.
								</p>
								<p>Performance Code Optimization
								</p>
								<p>I optimized the MolecularNodes code for scalability and large dataset handling by utilizing libraries such as MDAnalysis and SolvationAnalysis. These libraries are designed to optimize memory usage and improve code performance, which helps the code handle increasing computational demands and utilize efficient data structures. This optimization resulted in an efficient MolecularNodes code that can handle large datasets effectively. This illustrates the significance of code optimization in improving performance and scalability and shows the ability to leverage libraries and data structures to optimize code performance.
								</p>
								<p>Transfer technical concepts and techniques learned during the MMSSE program
								</p>
								<p>I applied the code optimization skill to optimize the MolecularNodes code for scalability and large dataset handling. We achieved this optimization by utilizing libraries such as MDAnalysis and SolvationAnalysis that are designed to optimize memory usage and improve code performance. This optimization allowed the MolecularNodes code to handle increasing computational demands and use efficient data structures, resulting in an efficient tool that can handle large datasets effectively. This showcases my proficiency in code optimization and highlights our ability to leverage libraries and data structures to optimize code performance, which is a valuable transferable skill learned during the MSSE program.
								</p>


												
								<hr />
								<header>
									<h2>GAN MNIST 
									</h2>
									<p>Highlighting Python Programming Skill</p>
								</header>
								<p>PyTorch was utilized to develop the architecture of a generative adversarial network (GAN) model for the MNIST dataset. The GAN model includes a generator and a discriminator that compete with each other. The generator takes a random vector of length 100 as input and generates images that are then fed into the discriminator alongside real images from the MNIST dataset. The discriminator outputs a probability value indicating whether the input image is real or fake (generated by the generator). This project showcases proficiency in Python programming, specifically in using PyTorch to develop and implement a complex machine learning model.
								<p>Best Software Practices</p>
								<p>I focused on documentation and organization while working on the GAN model for the MNIST dataset. Two multi-layer perceptions (MLPs) with four linear layers each were used for the generator and the discriminator, with the input to the generator being a random vector of length 100. LeakyReLU with a negative slope of 0.2 was used as the activation function for the hidden layers, and the model was trained using a learning rate of 0.0002 and a regularization technique of our choice. In addition to the GAN model implementation, the code was well-documented and easy to read, with clear comments and variable names that accurately reflected their purpose. We also organized the code into logical modules and functions to improve its readability and maintainability. This demonstrated knowledge of best software practices, highlighting the importance of producing high-quality, maintainable, and scalable software.

								</p>
								<p>Software Development Management Experience</p>
								<p>Jupyter notebooks were particularly important in building a deep-learning GAN model. By using Jupyter notebook, I demonstrated my ability to experiment with different parameters and architectures for deep learning models in an interactive and exploratory manner. This showed my proficiency in software development management and the ability to optimize deep-learning models for better performance. Overall, Jupyter notebooks were a valuable addition to my software portfolio, demonstrating my skills in software development management when working with deep-learning models.
								</p>
								<p>Algorithmic Competence</p>
								<p>GAN is a machine learning model consisting of a generator and a discriminator that compete with each other. The generator aims to generate realistic images, while the discriminator tries to distinguish between real and fake images. The code demonstrates my proficiency in implementing complex machine learning algorithms and understanding their underlying concepts, which are crucial in demonstrating algorithmic competence.
								<p>Performance Code Optimization
								</p>
								<p>Torch CUDA is an important package that is relevant to performing code optimization in the context of deep learning models. It allows PyTorch to interact with NVIDIA GPUs and accelerate computations performed in deep learning models. By offloading computations to the GPU, PyTorch can perform computations in parallel and speed up the training process of deep learning models, such as the GAN model applied to the MNIST dataset. The use of Torch CUDA is particularly relevant when parallelizing the training process of the GAN model, by allocating tensors to the GPU and taking advantage of its parallel processing capabilities. Additionally, torch.cuda provides methods to set up and run CUDA operations, keep track of the currently selected GPU, and handle cross-GPU operations.

								</p>
								<p>Transfer technical concepts and techniques learned during the MMSSE program
								</p>
								<p>The technical concepts being applied are related to deep learning and neural networks. Specifically, how to define and use two classes in PyTorch to implement a Generative Adversarial Network (GAN) on the MNIST dataset. The GAN is a type of neural network consisting of two parts: a generator and a discriminator. The generator takes a random input and produces a synthetic image, while the discriminator tries to distinguish between real and synthetic images. The two classes, Generator and Discriminator, define the neural networks used by the GAN.
								</p>
								<hr />


								<header>
									<h2>Optimizing Matrix Multiplication
									</h2>
									<p>Highlighting C++ Programming Skill</p>
								</header>
								<p>I implemented microkernel vectorization using AVX intrinsics, demonstrating my ability to optimize code for better performance. This involved manually providing instructions for parallelism in C++ instead of relying on the compiler, which required knowledge of C++ syntax and data types. I also ensured access to contiguous memory and cache alignment by using a function to pad and unpad matrices that worked with our microkernel vectorization. Additionally, I  used single instruction multiple data (SIMD or vectorization) to improve performance in C++. By utilizing vectorized instructions,  I was able to better utilize processor registers through manual loop unrolling, which helped avoid branch instructions and achieve significant performance improvements.
								</p>
								<p>Best Software Practices</p>
								<p>I prioritized documentation and organization when implementing the optimizations. Specifically, I documented the use of the multilevel blocking, microkernel vectorization, and repacking algorithms, as well as the reasons for their implementation. I also made note of the performance trade-offs I encountered, such as the longer padding time for smaller matrices. By clearly documenting my decision-making process and the steps I took to optimize the source code, I was able to create a more organized and understandable codebase. As a result, the code performance achieved a final performance improvement of 50.21%.

								</p>
								<p>Software Development Management Experience</p>
								<p>As part of my focus on software development management, I prioritized documentation and organization when implementing optimizations for my project. Specifically, I documented the use of multilevel blocking, microkernel vectorization, and repacking algorithms, as well as the reasons for their implementation. I also made note of performance trade-offs encountered, such as the longer padding time for smaller matrices. By clearly documenting my decision-making process and the steps I took to optimize the source code, I created a more organized and understandable codebase. This approach resulted in a final performance improvement of 50.21%. This demonstrates my ability to apply fundamental software project management principles, including the use of software productivity tools, to create a well-documented and organized software portfolio.

								</p>
								<p>Algorithmic Competence</p>
								<p>The demonstration of algorithmic competence went beyond knowledge of a particular software package, as shown by the implementation of an optimized DGEMM algorithm using various techniques. One such technique was microkernel vectorization, which utilized vectorization to enhance the innermost loop's performance. AVX-512 instructions were used to perform eight double precision floating point operations in a single instruction, resulting in significant performance improvements. In addition to this, I employed techniques such as loop reordering, multilevel blocking, and repacking to further optimize the algorithm. These optimizations resulted in a significant performance increase of 5% to 50%, showcasing my expertise in optimizing algorithms beyond just knowledge of a particular software package.
								</p>
								<p>Performance Code Optimization
								</p>
								<p>To optimize code performance, several techniques can be used, including loop reordering, microkernel vectorization, multilevel blocking, and repacking. Loop reordering improves cache efficiency and reduces cache misses by rearranging the order of loops to improve data locality. Microkernel vectorization optimizes code for modern processors with vector processing units, such as SIMD (Single Instruction Multiple Data) units, which can perform multiple arithmetic operations in parallel. Multilevel blocking divides the matrix into smaller blocks to reduce memory traffic and improve cache utilization. Repacking involves transposing the data in a matrix to improve cache locality and reduce cache misses. By implementing these techniques, code performance can be significantly improved.

								</p>
								<p>Transfer technical concepts and techniques learned during the MMSSE program
								</p>
								<p>I utilized a number of techniques to optimize the code performance, including loop reordering, microkernel vectorization, multilevel blocking, and repacking. Loop reordering was particularly effective in improving cache efficiency and reducing cache misses, achieved by rearranging the order of loops to improve data locality. Microkernel vectorization allowed me to optimize the code for modern processors with vector processing units, such as SIMD (Single Instruction Multiple Data) units, which can perform multiple arithmetic operations in parallel. Multilevel blocking was another technique that involved dividing the matrix into smaller blocks to reduce memory traffic and improve cache utilization. Lastly, I employed repacking, which involved transposing the data in a matrix to improve cache locality and reduce cache misses. These techniques resulted in a significant performance increase, demonstrating my proficiency in code optimization.
								</p>
								
								<hr />


								
								

				<!-- Footer -->
				<footer id="footer">
	
				</section>
				<section class="split contact">
					<section class="alt">
					</section>

					<section>
						<h3>Email</h3>
						<p><a href="#">joyce_kim1@berkeley.edu</a></p>
					</section>
					<section>
						<h3>Social</h3>
						<ul class="icons alt">
							<li><a href="#" class="icon brands alt fa-twitter"><span class="label">Twitter</span></a></li>
							<li><a href="#" class="icon brands alt fa-facebook-f"><span class="label">Facebook</span></a></li>
							<li><a href="#" class="icon brands alt fa-instagram"><span class="label">Instagram</span></a></li>
							<li><a href="https://github.com/kimjoyc?tab=repositories" class="icon brands alt fa-github"><span class="label">GitHub</span></a></li>
						</ul>
					</section>
				</section>
			</footer>

	</div>


		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>